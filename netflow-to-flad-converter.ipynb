{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils.binary_processing import split_flag_columns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from copy import copy\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"NF-CSE-CIC-IDS2018-v2-DDoS-downsample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_netflow = {\n",
    "    \"IPV4_SRC_ADDR\":                \"object\",\n",
    "    \"L4_SRC_PORT\":                  \"float32\",\n",
    "    \"IPV4_DST_ADDR\":                \"object\",\n",
    "    \"L4_DST_PORT\":                  \"float32\",\n",
    "    \"PROTOCOL\":                     \"float32\",\n",
    "    \"L7_PROTO\":                     \"float64\",\n",
    "    \"IN_BYTES\":                     \"float32\",\n",
    "    \"IN_PKTS\":                      \"float32\",\n",
    "    \"OUT_BYTES\":                    \"float32\",\n",
    "    \"OUT_PKTS\":                     \"float32\",\n",
    "    \"TCP_FLAGS\":                    \"int32\",\n",
    "    \"CLIENT_TCP_FLAGS\":             \"int32\",\n",
    "    \"SERVER_TCP_FLAGS\":             \"int32\",\n",
    "    \"FLOW_DURATION_MILLISECONDS\":   \"float32\",\n",
    "    \"DURATION_IN\":                  \"float32\",\n",
    "    \"DURATION_OUT\":                 \"float32\",\n",
    "    \"MIN_TTL\":                      \"float32\",\n",
    "    \"MAX_TTL\":                      \"float32\",\n",
    "    \"LONGEST_FLOW_PKT\":             \"float32\",\n",
    "    \"SHORTEST_FLOW_PKT\":            \"float32\",\n",
    "    \"MIN_IP_PKT_LEN\":               \"float32\",\n",
    "    \"MAX_IP_PKT_LEN\":               \"float32\",\n",
    "    \"SRC_TO_DST_SECOND_BYTES\":      \"float64\",\n",
    "    \"DST_TO_SRC_SECOND_BYTES\":      \"float64\",\n",
    "    \"RETRANSMITTED_IN_BYTES\":       \"float32\",\n",
    "    \"RETRANSMITTED_IN_PKTS\":        \"float32\",\n",
    "    \"RETRANSMITTED_OUT_BYTES\":      \"float32\",\n",
    "    \"RETRANSMITTED_OUT_PKTS\":       \"float32\",\n",
    "    \"SRC_TO_DST_AVG_THROUGHPUT\":    \"float32\",\n",
    "    \"DST_TO_SRC_AVG_THROUGHPUT\":    \"float32\",\n",
    "    \"NUM_PKTS_UP_TO_128_BYTES\":     \"float32\",\n",
    "    \"NUM_PKTS_128_TO_256_BYTES\":    \"float32\",\n",
    "    \"NUM_PKTS_256_TO_512_BYTES\":    \"float32\",\n",
    "    \"NUM_PKTS_512_TO_1024_BYTES\":   \"float32\",\n",
    "    \"NUM_PKTS_1024_TO_1514_BYTES\":  \"float32\",\n",
    "    \"TCP_WIN_MAX_IN\":               \"float32\",\n",
    "    \"TCP_WIN_MAX_OUT\":              \"float32\",\n",
    "    \"ICMP_TYPE\":                    \"float32\",\n",
    "    \"ICMP_IPV4_TYPE\":               \"float32\",\n",
    "    \"DNS_QUERY_ID\":                 \"float32\",\n",
    "    \"DNS_QUERY_TYPE\":               \"float32\",\n",
    "    \"DNS_TTL_ANSWER\":               \"float32\",\n",
    "    \"FTP_COMMAND_RET_CODE\":         \"float32\",\n",
    "    \"Attack\":                       \"object\",\n",
    "    \"Label\":                        \"float32\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_to_h5(set_x, set_y, filename):\n",
    "    hf = h5py.File(filename, 'w')\n",
    "    hf.create_dataset('set_x', data=set_x)\n",
    "    hf.create_dataset('set_y', data=set_y)\n",
    "    hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_to_drop() -> list: \n",
    "        \"\"\"\n",
    "            Attributes that bias the model and should be removed:\n",
    "                IPV4_SRC_ADDR = Source address of the information flow.\n",
    "                IPV4_DST_ADDR = Destination address of the information flow.\n",
    "                L7_PROTO = Layer 7 application protocol, specific to each type of DDoS attack.\n",
    "                L4_SRC_PORT = Source port of the communication flow.\n",
    "                L4_DST_PORT = Destination port of the communication flow.\n",
    "                FTP_COMMAND_RET_CODE = Return code of the FTP command.\n",
    "                Attack = Descriptive label of the example class. \n",
    "        \"\"\"\n",
    "        __features_to_drop = [\n",
    "            'Unnamed: 0',\n",
    "            'IPV4_SRC_ADDR', \n",
    "            'IPV4_DST_ADDR', \n",
    "            'L7_PROTO', \n",
    "            'L4_SRC_PORT', \n",
    "            'L4_DST_PORT', \n",
    "            'FTP_COMMAND_RET_CODE',\n",
    "            'Attack'\n",
    "        ]\n",
    "\n",
    "        return __features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset NF-CSE-CIC-IDS2018-v2-DDoS-downsample...\n",
      "Loaded dataset NF-CSE-CIC-IDS2018-v2-DDoS-downsample [OK]\n",
      "Initialized Columns Split Preprocessing.\n",
      "Using cached file: ec93b974b991f647501fb155031de7d4.\n",
      "Finished Columns Split Preprocessing. [OK]\n",
      "Experiments using the following columns: \n",
      "PROTOCOL\n",
      "IN_BYTES\n",
      "IN_PKTS\n",
      "OUT_BYTES\n",
      "OUT_PKTS\n",
      "FLOW_DURATION_MILLISECONDS\n",
      "DURATION_IN\n",
      "DURATION_OUT\n",
      "MIN_TTL\n",
      "MAX_TTL\n",
      "LONGEST_FLOW_PKT\n",
      "SHORTEST_FLOW_PKT\n",
      "MIN_IP_PKT_LEN\n",
      "MAX_IP_PKT_LEN\n",
      "SRC_TO_DST_SECOND_BYTES\n",
      "DST_TO_SRC_SECOND_BYTES\n",
      "RETRANSMITTED_IN_BYTES\n",
      "RETRANSMITTED_IN_PKTS\n",
      "RETRANSMITTED_OUT_BYTES\n",
      "RETRANSMITTED_OUT_PKTS\n",
      "SRC_TO_DST_AVG_THROUGHPUT\n",
      "DST_TO_SRC_AVG_THROUGHPUT\n",
      "NUM_PKTS_UP_TO_128_BYTES\n",
      "NUM_PKTS_128_TO_256_BYTES\n",
      "NUM_PKTS_256_TO_512_BYTES\n",
      "NUM_PKTS_512_TO_1024_BYTES\n",
      "NUM_PKTS_1024_TO_1514_BYTES\n",
      "TCP_WIN_MAX_IN\n",
      "TCP_WIN_MAX_OUT\n",
      "ICMP_TYPE\n",
      "ICMP_IPV4_TYPE\n",
      "DNS_QUERY_ID\n",
      "DNS_QUERY_TYPE\n",
      "DNS_TTL_ANSWER\n",
      "URGENT_POINTER\n",
      "ACKNOWLEDGEMENT\n",
      "PUSH\n",
      "RESET\n",
      "SYNCHRONISATION\n",
      "FIN\n",
      "CLIENT_URGENT_POINTER\n",
      "CLIENT_ACKNOWLEDGEMENT\n",
      "CLIENT_PUSH\n",
      "CLIENT_RESET\n",
      "CLIENT_SYNCHRONISATION\n",
      "CLIENT_FIN\n",
      "SERVER_URGENT_POINTER\n",
      "SERVER_ACKNOWLEDGEMENT\n",
      "SERVER_PUSH\n",
      "SERVER_RESET\n",
      "SERVER_SYNCHRONISATION\n",
      "SERVER_FIN\n"
     ]
    }
   ],
   "source": [
    "# Load Netflow Datasets\n",
    "print(f\"Loading dataset {DATASET_NAME}...\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f\"{os.getcwd()}/anomaly-flow-datasets/{DATASET_NAME}.csv.gz\",\n",
    "    dtype=dtypes_netflow\n",
    ")\n",
    "\n",
    "print(f\"Loaded dataset {DATASET_NAME} [OK]\")\n",
    "\n",
    "# Preprocessing to perform one-hot encoding of descriptive attributes.\n",
    "print(\"Initialized Columns Split Preprocessing.\")\n",
    "\n",
    "df = split_flag_columns(df)\n",
    "\n",
    "print(\"Finished Columns Split Preprocessing. [OK]\")\n",
    "\n",
    "# Remove unused features for training.\n",
    "df.drop(get_features_to_drop(), axis=1, inplace=True)\n",
    "\n",
    "# Preprocessing to remove very large values.\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "threshold = np.finfo(np.float32).max\n",
    "df = df[df < threshold]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X, y = df.drop(['Label'], axis=1), df['Label']\n",
    "columns = X.columns\n",
    "\n",
    "print('Experiments using the following columns: ')\n",
    "print(*list(columns), sep='\\n')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=SEED, shuffle=True)\n",
    "\n",
    "# Normalize the data between 0 and 1 (FLAD output)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_size = None\n",
    "\n",
    "if train_size is None:\n",
    "    scaler.fit(X_train[y_train == 0])\n",
    "    X_train = scaler.transform(X_train)\n",
    "    y_train = y_train\n",
    "else:\n",
    "    self.scaler.fit(X_train[y_train == 0])\n",
    "    X_train = scaler.transform(X_train[:train_size])\n",
    "    y_train = y_train[:train_size]\n",
    "\n",
    "validation_benign_samples = math.floor(0.1 * np.count_nonzero(y_train == 0))\n",
    "validation_attack_samples = math.floor(0.1 * np.count_nonzero(y_train == 1))\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = copy(X_test) \n",
    "y_test = copy(y_test)\n",
    "\n",
    "# Save the datasets\n",
    "save_dataset_to_h5(X_train, y_train, f'{DATASET_NAME}-train.hdf5')\n",
    "save_dataset_to_h5(X_test, y_test, f'{DATASET_NAME}-test.hdf5')\n",
    "save_dataset_to_h5(X_train[:validation_benign_samples], y_train[:validation_benign_samples], f'{DATASET_NAME}-val.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
